name: Regression Testing CI

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch: {}

permissions:
  contents: read
  actions: read
  checks: write
  pull-requests: write

env:
  SPRING_DATASOURCE_URL: jdbc:mysql://127.0.0.1:3306/automation_testing?useSSL=false&allowPublicKeyRetrieval=true&serverTimezone=UTC
  SPRING_DATASOURCE_USERNAME: root
  SPRING_DATASOURCE_PASSWORD: root@123

jobs:
  regression-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    services:
      mysql:
        image: mysql:8.0
        ports:
          - 3306:3306
        env:
          MYSQL_ROOT_PASSWORD: root@123
          MYSQL_DATABASE: automation_testing
        options: >-
          --health-cmd="mysqladmin ping --silent"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10

    steps:
      # 🧩 Step 1: Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4

      # ☕ Step 2: Set up Java 21 with Maven cache
      - name: Set up JDK 21 and Maven cache
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: '21'
          cache: maven

      # 🌐 Step 3: Install Chrome for Selenium (Updated method)
      - name: Install Google Chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable
        id: setup-chrome

      # 🔧 Step 4: Display Chrome version and setup ChromeDriver
      - name: Setup ChromeDriver
        run: |
          echo "✅ Chrome installed at: ${{ steps.setup-chrome.outputs.chrome-path }}"
          google-chrome --version
          # ChromeDriver will be managed by WebDriverManager in the code

      # 🕒 Step 5: Wait for MySQL to be ready
      - name: Wait for MySQL to be ready
        run: |
          sudo apt-get update && sudo apt-get install -y mysql-client
          echo "⏳ Waiting for MySQL to be ready..."
          for i in {1..30}; do
            if mysql -h 127.0.0.1 -P 3306 -u root -proot@123 -e "SELECT 1;" &>/dev/null; then
              echo "✅ MySQL is ready!"
              mysql -h 127.0.0.1 -P 3306 -u root -proot@123 -e "SHOW DATABASES;"
              break
            fi
            echo "⏳ Attempt $i/30 - MySQL not ready yet..."
            sleep 2
          done

      # 🧹 Step 6: Clean and prepare directories
      - name: Clean and prepare test directories
        working-directory: regression-test-suite
        run: |
          echo "🧹 Cleaning old reports and artifacts..."
          rm -rf test-output/reports/* || true
          rm -rf artifacts/* || true
          rm -rf target/surefire-reports/* || true
          
          # Create necessary directories
          mkdir -p test-output/reports
          mkdir -p artifacts
          mkdir -p target/surefire-reports
          
          echo "📁 Directory structure:"
          ls -la

      # 🔧 Step 7: Make Maven wrapper executable
      - name: Make Maven wrapper executable
        working-directory: regression-test-suite
        run: |
          chmod +x ./mvnw
          echo "✅ Maven wrapper is now executable"

      # 🧠 Step 8: Run Regression Test Suite
      - name: Run Regression Tests (CombinedSuiteRunner)
        working-directory: regression-test-suite
        env:
          HEADLESS: true
          CHROME_BIN: ${{ steps.setup-chrome.outputs.chrome-path }}
        run: |
          echo "🚀 Starting CombinedSuiteRunner execution..."
          echo "📊 Test Configuration:"
          echo "  - Headless Mode: $HEADLESS"
          echo "  - Chrome Path: $CHROME_BIN"
          echo "  - MySQL URL: $SPRING_DATASOURCE_URL"
          
          # First, let's check if Spring Boot application starts properly
          echo "🔍 Checking Spring Boot context..."
          ./mvnw clean compile test-compile
          
          # Check if the test class exists
          echo "🔍 Verifying test class exists..."
          find . -name "CombinedSuiteRunner.java" -type f
          
          # List all test classes
          echo "📋 Available test classes:"
          find src/test/java -name "*.java" -type f
          
          # First, test if Spring Boot context loads properly
          echo "🔍 Testing Spring Boot context loading..."
          ./mvnw test \
            -Dtest=com.testframework.regression.RegressionTestSuiteFrameworkApplicationTests \
            -Dspring.profiles.active=test \
            -Dmaven.test.failure.ignore=true \
            || echo "⚠️ Spring Boot context test failed"
          
          # Run diagnostic test to check framework components
          echo "🔍 Running diagnostic test..."
          ./mvnw test \
            -Dtest=tests.diagnostic.SpringContextDiagnosticTest \
            -Dspring.profiles.active=test \
            -Dmaven.test.failure.ignore=true \
            || echo "⚠️ Diagnostic test failed"
          
          # Run the main regression test with detailed logging
          echo "🚀 Running tests with detailed logging..."
          ./mvnw test \
            -Dtest=tests.combined.CombinedSuiteRunner \
            -Dspring.profiles.active=test \
            -Dmaven.test.failure.ignore=false \
            -Dselenium.headless=true \
            -Dsurefire.printSummary=true \
            -Dsurefire.useFile=true \
            -Dsurefire.reportFormat=xml \
            -Dlogging.level.com.testframework=DEBUG \
            -Dlogging.level.tests=DEBUG \
            -Dlogging.level.org.springframework.boot=INFO \
            -Dlogging.level.org.springframework.context=INFO \
            || echo "❌ Test execution failed, but continuing to collect logs..."
        continue-on-error: true

      # 📄 Step 9: Debug - List all generated files
      - name: Debug - List generated reports and artifacts
        if: always()
        working-directory: regression-test-suite
        run: |
          echo "=== 📊 SUREFIRE REPORTS ==="
          find target/surefire-reports -type f -name "*.xml" -o -name "*.txt" 2>/dev/null || echo "No surefire reports found"
          
          echo "=== 📄 SUREFIRE REPORT CONTENTS ==="
          if [ -d "target/surefire-reports" ]; then
            for file in target/surefire-reports/*.xml; do
              if [ -f "$file" ]; then
                echo "📄 Contents of $file:"
                cat "$file" | head -50
                echo "--- End of $file ---"
              fi
            done
          fi
          
          echo "=== 📈 CUSTOM REPORTS ==="
          find test-output -type f 2>/dev/null || echo "No custom reports found"
          
          echo "=== 📸 ARTIFACTS ==="
          find artifacts -type f 2>/dev/null || echo "No artifacts found"
          
          echo "=== 📁 FULL DIRECTORY STRUCTURE ==="
          ls -la
          ls -la target/ 2>/dev/null || echo "No target directory"
          
          echo "=== 🔍 MAVEN BUILD LOGS ==="
          if [ -f "target/surefire-reports/TEST-tests.combined.CombinedSuiteRunner.xml" ]; then
            echo "📄 Test execution XML found"
          else
            echo "❌ No test execution XML found"
          fi
          
          echo "=== 🔍 SPRING BOOT LOGS ==="
          find . -name "*.log" -type f 2>/dev/null || echo "No log files found"
          
          echo "=== 🔍 MAVEN SUREFIRE LOGS ==="
          if [ -d "target/surefire-reports" ]; then
            ls -la target/surefire-reports/
            echo "📄 Surefire text reports:"
            find target/surefire-reports -name "*.txt" -exec echo "=== {} ===" \; -exec cat {} \;
          fi

      # 📊 Step 10: Publish Test Results to GitHub
      - name: Publish Test Results
        uses: dorny/test-reporter@v1
        if: always() && hashFiles('regression-test-suite/target/surefire-reports/*.xml') != ''
        with:
          name: Regression Test Results
          path: 'regression-test-suite/target/surefire-reports/*.xml'
          reporter: java-junit
          fail-on-error: false

      # 📦 Step 11: Upload Surefire Test Reports
      - name: Upload Surefire Test Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: surefire-reports-${{ github.run_number }}
          path: |
            regression-test-suite/target/surefire-reports/**/*
          retention-days: 30
          if-no-files-found: warn

      # 📈 Step 12: Upload Custom HTML & CSV Reports
      - name: Upload Custom Test Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: custom-test-reports-${{ github.run_number }}
          path: |
            regression-test-suite/test-output/**/*.html
            regression-test-suite/test-output/**/*.csv
            regression-test-suite/test-output/**/*.xml
            regression-test-suite/test-output/**/*.json
          retention-days: 30
          if-no-files-found: warn

      # 🖼️ Step 13: Upload Screenshots & Artifacts
      - name: Upload Test Artifacts (Screenshots, Logs, etc.)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-artifacts-${{ github.run_number }}
          path: |
            regression-test-suite/artifacts/**/*
          retention-days: 30
          if-no-files-found: warn

      # 📋 Step 14: Upload Maven Logs
      - name: Upload Maven Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: maven-logs-${{ github.run_number }}
          path: |
            regression-test-suite/target/**/*.log
          retention-days: 7
          if-no-files-found: ignore

      # 📝 Step 15: Generate Test Summary
      - name: Generate Test Summary
        if: always()
        working-directory: regression-test-suite
        run: |
          echo "## 🧪 Regression Test Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Execution Time**: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "- **Run Number**: ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Count test files
          SUREFIRE_COUNT=$(find target/surefire-reports -name "*.xml" 2>/dev/null | wc -l || echo "0")
          CUSTOM_COUNT=$(find test-output -name "*.html" -o -name "*.csv" 2>/dev/null | wc -l || echo "0")
          ARTIFACT_COUNT=$(find artifacts -type f 2>/dev/null | wc -l || echo "0")
          
          echo "### 📊 Generated Files:" >> $GITHUB_STEP_SUMMARY
          echo "- **Surefire Reports**: $SUREFIRE_COUNT files" >> $GITHUB_STEP_SUMMARY
          echo "- **Custom Reports**: $CUSTOM_COUNT files" >> $GITHUB_STEP_SUMMARY
          echo "- **Artifacts**: $ARTIFACT_COUNT files" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📥 Download Artifacts:" >> $GITHUB_STEP_SUMMARY
          echo "All reports and artifacts are available in the **Artifacts** section of this workflow run." >> $GITHUB_STEP_SUMMARY
